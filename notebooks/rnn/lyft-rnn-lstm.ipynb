{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nimport os\nfrom pathlib import Path\nimport random\nimport sys\n\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.core.display import display, HTML\n\n# --- plotly ---\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\n\n# --- models ---\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\n\n# --- setup ---\npd.set_option('max_columns', 50)","execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import zarr\n\nimport l5kit\nfrom l5kit.data import ChunkedDataset, LocalDataManager\nfrom l5kit.dataset import EgoDataset, AgentDataset\n\nfrom l5kit.rasterization import build_rasterizer\nfrom l5kit.configs import load_config_data\nfrom l5kit.visualization import draw_trajectory, TARGET_POINTS_COLOR\nfrom l5kit.geometry import transform_points\nfrom tqdm import tqdm\nfrom collections import Counter\nfrom l5kit.data import PERCEPTION_LABELS\nfrom prettytable import PrettyTable\n\nfrom matplotlib import animation, rc\nfrom IPython.display import HTML\n\nrc('animation', html='jshtml')\nprint(\"l5kit version:\", l5kit.__version__)","execution_count":2,"outputs":[{"output_type":"stream","text":"l5kit version: 1.1.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\nfrom keras.optimizers import SGD\nimport math\nfrom sklearn.metrics import mean_squared_error","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom datetime import datetime","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.environ[\"L5KIT_DATA_FOLDER\"] = \"/kaggle/input/lyft-motion-prediction-autonomous-vehicles\"","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dm = LocalDataManager()\ndataset_path = dm.require('scenes/sample.zarr')\nzarr_dataset = ChunkedDataset(dataset_path)\nzarr_dataset.open()\nprint(zarr_dataset)","execution_count":6,"outputs":[{"output_type":"stream","text":"+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n|    100     |   24838    |  1893736   |     316008    |       0.69      |        248.38        |        76.24         |        24.83         |        10.00        |\n+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(zarr_dataset.agents)\nprint(zarr_dataset.agents.shape)\nn = zarr_dataset.agents.shape","execution_count":7,"outputs":[{"output_type":"stream","text":"<zarr.core.Array '/agents' (1893736,) [('centroid', '<f8', (2,)), ('extent', '<f4', (3,)), ('yaw', '<f4'), ('velocity', '<f4', (2,)), ('track_id', '<u8'), ('label_probabilities', '<f4', (17,))] read-only>\n(1893736,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper to convert a timedelta to a string (dropping milliseconds)\ndef deltaToString(delta):\n    timeObj = time.gmtime(delta.total_seconds())\n    return time.strftime('%H:%M:%S', timeObj)\n\nclass ProgressBar:\n    \n    # constructor\n    #   maxIterations: maximum number of iterations\n    def __init__(self, maxIterations):\n        self.maxIterations = maxIterations\n        self.granularity = 100 # 1 whole percent\n    \n    # start the timer\n    def start(self):\n        self.start = datetime.now()\n    \n    # check the progress of the current iteration\n    #   # currentIteration: the current iteration we are on\n    def check(self, currentIteration, chunked=False):\n        if currentIteration % round(self.maxIterations / self.granularity) == 0 or chunked:\n            \n            percentage = round(currentIteration / (self.maxIterations - self.maxIterations / self.granularity) * 100)\n            \n            current = datetime.now()\n            \n            # time calculations\n            timeElapsed = (current - self.start)\n            timePerStep = timeElapsed / (currentIteration + 1)\n            totalEstimatedTime = timePerStep * self.maxIterations\n            timeRemaining = totalEstimatedTime - timeElapsed\n            \n            # string formatting\n            percentageStr = \"{:>3}%  \".format(percentage)\n            remainingStr = \"Remaining: {}  \".format(deltaToString(timeRemaining))\n            elapsedStr = \"Elapsed: {}  \".format(deltaToString(timeElapsed))\n            totalStr = \"Total: {}\\r\".format(deltaToString(totalEstimatedTime))\n            \n            print(percentageStr + remainingStr + elapsedStr + totalStr, end=\"\")\n\n    def end(self):\n        print()","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getAgentsChunked(dataset, subsetPercent=1, chunks=10):\n\n    datasetLength = round(len(dataset) * subsetPercent)\n    chunkSize = round(datasetLength / chunks)\n    \n    pb = ProgressBar(datasetLength)\n    pb.start()\n\n    agents = []\n    for i in range(0, datasetLength, chunkSize):\n\n        agentsSubset = dataset[i:i+chunkSize]\n        for j in range(0,len(agentsSubset)):\n\n            agent = agentsSubset[j]\n            track_id = agent[4]\n\n            if track_id >= len(agents):\n                agents.append([])\n\n            data = []\n            centroid = agent[0]\n            yaw = agent[2]\n            velocity = agent[3]\n            data.append(centroid[0])\n            data.append(centroid[1])\n            data.append(yaw)\n            data.append(velocity[0])\n            data.append(velocity[1])\n            agents[int(track_id)-1].append(data)\n        pb.check(i, True)\n\n    return agents","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(zarr_dataset.agents, \"\\n\")\nprint(type(zarr_dataset.agents[0][0][0]))\nprint(type(zarr_dataset.agents[0][0]))\nprint(type(zarr_dataset.agents[0]))\nprint(type(zarr_dataset.agents))\nagents = []\nprint(type(agents))","execution_count":10,"outputs":[{"output_type":"stream","text":"<zarr.core.Array '/agents' (1893736,) [('centroid', '<f8', (2,)), ('extent', '<f4', (3,)), ('yaw', '<f4'), ('velocity', '<f4', (2,)), ('track_id', '<u8'), ('label_probabilities', '<f4', (17,))] read-only> \n\n<class 'numpy.float64'>\n<class 'numpy.ndarray'>\n<class 'numpy.void'>\n<class 'zarr.core.Array'>\n<class 'list'>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"subsetPercent = 1 #1*10**-2\nprint(subsetPercent)\nagents = getAgentsChunked(zarr_dataset.agents, subsetPercent, 100)","execution_count":11,"outputs":[{"output_type":"stream","text":"1\n 41%  Remaining: 00:00:15  Elapsed: 00:00:10  Total: 00:00:26\r","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-7225ee8edddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msubsetPercent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m#1*10**-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsetPercent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0magents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAgentsChunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzarr_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsetPercent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-4c1e4e884f3f>\u001b[0m in \u001b[0;36mgetAgentsChunked\u001b[0;34m(dataset, subsetPercent, chunks)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mcentroid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0myaw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mvelocity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotAgents(agents):\n    r = lambda: random.randint(0,255)\n    pb = ProgressBar(len(agents))\n    pb.start()\n    for i in range(0, len(agents)):\n        agent = agents[i]\n        centroid_x = []\n        centroid_y = []\n        for centroid in agent:\n            centroid_x.append(centroid[0])\n            centroid_y.append(centroid[1])\n        plt.plot(centroid_x, centroid_y, 'o', color='#%02X%02X%02X' % (r(),r(),r()))\n        pb.check(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotAgents(agents)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalizeAgents(agents):\n    dataForNormalization = []\n    pb = ProgressBar(len(agents))\n    pb.start()\n    for agent in agents:\n        pb.check(0, True)\n        for data in agent:\n            for i in range(0, len(data)):\n                feature = data[i]\n                if i >= len(dataForNormalization):\n                    dataForNormalization.append([])\n                dataForNormalization[i].append(feature)\n        \n    \n    first = True\n    normalizedAgents = []\n    pb = ProgressBar(len(dataForNormalization) * len(agents))\n    pb.start()\n    for i in range(0, len(dataForNormalization)):\n        pb.end()\n        data = dataForNormalization[i]\n        min_ = np.min(data)\n        max_ = np.max(data)\n        print(\"max[{}]\".format(i),np.max(data))\n        print(\"min[{}]\".format(i),np.min(data))\n        \n        for j in range(0, len(agents)):\n            pb.check(i * j)\n            if j >= len(normalizedAgents):\n                normalizedAgents.append([])\n                \n            agent = agents[j]\n            normalizedAgent = normalizedAgents[j]\n            \n            for k in range(0, len(agent)):\n                if k >= len(normalizedAgent):\n                    normalizedAgent.append([])\n                data = agent[k]\n                normalizedData = normalizedAgent[k]\n                \n                feature = data[i]\n                normalizedFeature = (feature - min_) / (max_ - min_)\n                if i == 0 and first:\n                    print(feature)\n                    print(normalizedFeature)\n                    first = False\n                \n                if i >= len(normalizedData):\n                    normalizedData.append(0)\n                normalizedData[i] = normalizedFeature\n    return normalizedAgents","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalizedAgents = normalizeAgents(agents)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(agents))\nprint(len(normalizedAgents),\"\\n\")\n\nprint(agents[0][0][0])\nprint(normalizedAgents[0][0][0],\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def printAgentsInfo(agents, limit):\n    print(\"len(agents)\", len(agents), \"\\n\")\n\n    agentCentroidLengths = []\n    agentsOverLimit = []\n    for agent in agents:\n        agentCentroidLengths.append(len(agent))\n        if len(agent) > limit:\n            agentsOverLimit.append(agent)\n\n    print(\"len(agentCentroidLengths)\",len(agentCentroidLengths), \"\\n\")\n\n    print(\"max\",np.max(agentCentroidLengths))\n    print(\"min\",np.min(agentCentroidLengths))\n    print(\"mean\",np.mean(agentCentroidLengths))\n    print(\"std\",np.std(agentCentroidLengths), \"\\n\")\n\n    print(\"agents with {}+ history\".format(limit),len(agentsOverLimit))\n    return agentsOverLimit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"limit = 10\nagentsOverLimit = printAgentsInfo(normalizedAgents, limit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getTrainingSets(agents, limit):\n    allTrainingSets = []\n    totalNumberOfTrainingSets = 0\n    \n    pb = ProgressBar(len(agentsOverLimit))\n    pb.start()\n    for i in range(0, len(agentsOverLimit)):\n        agent = agentsOverLimit[i]\n        agentTrainingSets = []\n        for i in range(limit, len(agent)-1):\n            agentTrainingSet = []\n\n            start = i - limit\n            end = i\n            output = i + 1\n\n            agentTrainingSet.append(agent[start:end])\n            agentTrainingSet.append(agent[output])\n            agentTrainingSets.append(agentTrainingSet)\n\n            totalNumberOfTrainingSets = totalNumberOfTrainingSets + 1\n\n        allTrainingSets.append(agentTrainingSets)\n        pb.check(i)\n\n    print(\"len(allTrainingSets)\", len(allTrainingSets))\n    print(\"len(allTrainingSets[0])\",len(allTrainingSets[0]), \"\\n\")\n\n    print(\"len(agentsOverLimit)\",len(agentsOverLimit))\n    print(\"len(agentsOverLimit[0]) - limit - 1\",len(agentsOverLimit[0]) - limit - 1, \"\\n\")\n\n    print(\"totalNumberOfTrainingSets\",totalNumberOfTrainingSets)\n    return allTrainingSets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"allTrainingSets = getTrainingSets(agentsOverLimit, limit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def flattenTrainingSets(allTrainingSets):\n    allTrainingSetsFlattened_X = []\n    allTrainingSetsFlattened_Y = []\n    for allTrainingSet in allTrainingSets:\n        for trainingSet in allTrainingSet:\n            allTrainingSetsFlattened_X.append(trainingSet[0])\n            allTrainingSetsFlattened_Y.append(trainingSet[1])\n    print(\"len(allTrainingSetsFlattened_X)\", len(allTrainingSetsFlattened_X))\n    return allTrainingSetsFlattened_X, allTrainingSetsFlattened_Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"allTrainingSetsFlattened_X, allTrainingSetsFlattened_Y = flattenTrainingSets(allTrainingSets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reshapeFlattenedTrainingSets(allTrainingSetsFlattened_X, allTrainingSetsFlattened_Y):\n    length = len(allTrainingSetsFlattened_X)\n    depth = len(allTrainingSetsFlattened_X[0])\n    channels = len(allTrainingSetsFlattened_X[0][0])\n\n    print(\"length\", length)\n    print(\"depth\", depth)\n    print(\"channels\",channels)\n    print(\"length*depth*channels\",length*depth*channels)\n\n    allTrainingSetsFlattened_Input = np.reshape(allTrainingSetsFlattened_X, (length,depth,channels))\n    allTrainingSetsFlattened_Output = np.reshape(allTrainingSetsFlattened_Y, (length,1,channels))\n\n    print(allTrainingSetsFlattened_Input.shape[1])\n    print(allTrainingSetsFlattened_Input.shape[2])\n    \n    return allTrainingSetsFlattened_Input, allTrainingSetsFlattened_Output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"allTrainingSetsFlattened_Input = allTrainingSetsFlattened_X\nallTrainingSetsFlattened_Output = allTrainingSetsFlattened_Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"allTrainingSetsFlattened_Input, allTrainingSetsFlattened_Output = reshapeFlattenedTrainingSets(allTrainingSetsFlattened_X, allTrainingSetsFlattened_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The LSTM architecture\nregressor = Sequential()\n# First LSTM layer with Dropout regularisation\nregressor.add(LSTM(units=50, return_sequences=True, input_shape=(allTrainingSetsFlattened_Input.shape[1],allTrainingSetsFlattened_Input.shape[2])))\nregressor.add(Dropout(0.2))\n# Second LSTM layer\nregressor.add(LSTM(units=50, return_sequences=True))\nregressor.add(Dropout(0.2))\n# Third LSTM layer\nregressor.add(LSTM(units=50, return_sequences=True))\nregressor.add(Dropout(0.2))\n# Fourth LSTM layer\nregressor.add(LSTM(units=50))\nregressor.add(Dropout(0.2))\n# The output layer\nregressor.add(Dense(units=allTrainingSetsFlattened_Input.shape[2]))\n\n# Compiling the RNN\nregressor.compile(optimizer='rmsprop',loss='mean_squared_error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting to the training set\n\nclass CustomCallback(keras.callbacks.Callback):\n    \n    def __init__(self):\n        self.epoch = 0\n        \n    def on_epoch_end(self, epoch, logs=None):\n        keys = list(logs.keys())\n        print(\"Epoch: {}             loss: {}\\n\".format(self.epoch, logs['loss']), end=\"\")\n        self.epoch = epoch\n\n    def on_train_batch_end(self, batch, logs=None):\n        keys = list(logs.keys())\n        if batch % 100 == 0:\n            print(\"Epoch: {} batchs: {}% loss: {}\\r\".format(self.epoch, round(batch / self.params['steps'] * 100), logs['loss']), end=\"\")\n\nregressor.fit(allTrainingSetsFlattened_Input,allTrainingSetsFlattened_Output,epochs=2,batch_size=128,verbose=0,callbacks=[CustomCallback()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_path_test = dm.require('scenes/test.zarr')\nzarr_dataset_test = ChunkedDataset(dataset_path_test)\nzarr_dataset_test.open()\nprint(zarr_dataset_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(zarr_dataset_test.agents))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subsetPercent = 1*10**-3\nprint(subsetPercent)\nagentsTest = getAgentsChunked(zarr_dataset_test.agents, subsetPercent, 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotAgents(agents)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalizedAgentsTest = normalizeAgents(agentsTest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agentsTestOverLimit = printAgentsInfo(normalizedAgentsTest, limit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"allTestingSets = getTrainingSets(agentsTestOverLimit, limit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"allTestingSetsFlattened_X, allTestingSetsFlattened_Y = flattenTrainingSets(allTestingSets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"allTestingSetsFlattened_Input, allTestingSetsFlattened_Output = reshapeFlattenedTrainingSets(allTestingSetsFlattened_X, allTestingSetsFlattened_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max = len(allTestingSetsFlattened_Input)\nprint(max)\nchunkSize = 1000\npb = ProgressBar(max)\npb.start()\npredictedTestAgentCentroid = np.empty((1,5))\nfor i in range(0, max-chunkSize, chunkSize):#len(zarr_dataset.agents)):\n    newPredictions = regressor.predict(allTestingSetsFlattened_Input[i:i+chunkSize])\n    predictedTestAgentCentroid = np.concatenate((predictedTestAgentCentroid, newPredictions))\n    pb.check(i, True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(predictedTestAgentCentroid))\npredictedTestAgentCentroid = predictedTestAgentCentroid[1:len(predictedTestAgentCentroid)]\nprint(len(predictedTestAgentCentroid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"randomSamples = 10\nfor i in range(0, len(predictedTestAgentCentroid), round(len(predictedTestAgentCentroid) / randomSamples)):\n    testSet = allTestingSetsFlattened_Input[i]\n    print(testSet[0][0])\n    print(predictedTestAgentCentroid[i][0],\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}